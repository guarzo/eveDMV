# credo:disable-for-this-file Credo.Check.Refactor.ModuleDependencies
# credo:disable-for-this-file Credo.Check.Readability.StrictModuleLayout
defmodule EveDmvWeb.CorporationLive do
  import EveDmvWeb.Components.ErrorStateComponent
  import EveDmvWeb.Components.EmptyStateComponent
  import EveDmvWeb.Components.ThreatLevelComponent
  import EveDmvWeb.Components.ActivityOverviewComponent
  import EveDmvWeb.Components.IskStatsComponent
  import EveDmvWeb.EveImageComponents
  import EveDmvWeb.FormatHelpers
  alias Ecto.Adapters.SQL
  alias EveDmv.Api
  alias EveDmv.Analytics.BattleDetector
  alias EveDmv.Cache.AnalysisCache
  alias EveDmv.Contexts.CorporationIntelligence
  alias EveDmv.Eve.EsiCorporationClient
  alias EveDmv.Eve.NameResolver
  alias EveDmv.Killmails.Participant
  alias EveDmv.Performance.BatchNameResolver
  alias EveDmv.Repo
  alias EveDmvWeb.Helpers.TimeFormatter
  alias EveDmvWeb.CorporationLive.DataLoader
  require Ash.Query
  require Logger

  @moduledoc """
  LiveView for displaying corporation overview and member activity.

  Shows corporation statistics, member list, recent activity, and
  top performing pilots within the corporation.
  """

  use EveDmvWeb, :live_view

  # Load current user from session on mount
  on_mount({EveDmvWeb.AuthLive, :load_from_session})
  # Import reusable components
  # Template helper functions
  def format_relative_time(datetime) do
    TimeFormatter.format_friendly_time(datetime)
  end

  @impl Phoenix.LiveView
  def mount(%{"corporation_id" => corp_id_str}, _session, socket) do
    case Integer.parse(corp_id_str) do
      {corporation_id, ""} ->
        # Start with loading state
        socket =
          socket
          |> assign(:loading, true)
          |> assign(:corporation_id, corporation_id)
          |> assign(:error, nil)
          |> assign(:active_tab, "overview")

        # Load data asynchronously
        send(self(), :load_corporation_data)

        {:ok, socket}

      _ ->
        socket =
          socket
          |> assign(:error, "Invalid corporation ID")
          |> assign(:loading, false)

        {:ok, socket}
    end
  end

  @impl Phoenix.LiveView
  def handle_info(:load_corporation_data, socket) do
    corporation_id = socket.assigns.corporation_id

    # Load all data using the optimized data loader
    case load_all_corporation_data(corporation_id) do
      {:ok, data} ->
        socket =
          socket
          |> assign(:loading, false)
          |> assign(:error, nil)
          |> assign(:corp_info, data.info)
          |> assign(:corp_stats, data.stats.last_30_days)
          |> assign(:comprehensive_stats, data.stats)
          |> assign(:timezone_data, data.timezone)
          |> assign(:ship_usage, data.ships)
          |> assign(:location_stats, data.location_stats || %{})
          |> assign(:victim_stats, data.victim_stats || %{})
          |> assign(:intelligence_data, data.intelligence)
          |> assign(:recent_battles, data.battles)
          |> assign(:battle_stats, data.battle_stats)
          |> assign(:fleet_doctrines, data.fleet_doctrines)
          |> assign(:participation_data, calculate_participation_data(data.members, data.info))
          # Sprint 15A: Convert large datasets to streams for memory efficiency
          |> stream(:members, data.members || [], at: -1, dom_id: &"member-#{&1.character_id}")
          |> stream(:recent_activity, data.activity || [],
            at: -1,
            dom_id: &"activity-#{&1.killmail_id}-#{&1.character_id}"
          )

        {:noreply, socket}

      {:error, reason} ->
        Logger.error("Failed to load corporation data: #{inspect(reason)}")

        socket =
          socket
          |> assign(:loading, false)
          |> assign(:error, "Failed to load corporation data")

        {:noreply, socket}
    end
  end

  @impl Phoenix.LiveView
  def handle_event("refresh", _params, socket) do
    corporation_id = socket.assigns.corporation_id

    # Invalidate cache for this corporation
    AnalysisCache.invalidate_corporation(corporation_id)

    # Show loading state
    socket =
      socket
      |> assign(:loading, true)
      |> put_flash(:info, "Refreshing corporation data...")

    # Reload data asynchronously
    send(self(), :load_corporation_data)

    {:noreply, socket}
  end

  # Sprint 15A: Pagination handlers for large datasets
  def handle_event("paginate_members_next", %{"cursor" => cursor}, socket) do
    corporation_id = socket.assigns.corporation_id
    page_size = socket.assigns[:members_page_size] || 50

    case EveDmv.Pagination.CursorPaginator.paginate_corporation_members(
           corporation_id,
           after: cursor,
           page_size: page_size
         ) do
      paginator ->
        pagination = EveDmv.Pagination.CursorPaginator.pagination_assigns(paginator)

        socket =
          socket
          |> stream(:members, pagination.items, at: -1, dom_id: &"member-#{&1.character_id}")
          |> assign(:members_pagination, pagination)

        {:noreply, socket}
    end
  end

  def handle_event("paginate_members_prev", %{"cursor" => cursor}, socket) do
    corporation_id = socket.assigns.corporation_id
    page_size = socket.assigns[:members_page_size] || 50

    case EveDmv.Pagination.CursorPaginator.paginate_corporation_members(
           corporation_id,
           before: cursor,
           page_size: page_size
         ) do
      paginator ->
        pagination = EveDmv.Pagination.CursorPaginator.pagination_assigns(paginator)

        socket =
          socket
          |> stream(:members, pagination.items, reset: true, dom_id: &"member-#{&1.character_id}")
          |> assign(:members_pagination, pagination)

        {:noreply, socket}
    end
  end

  def handle_event("paginate_members_size", %{"value" => size_str}, socket) do
    corporation_id = socket.assigns.corporation_id
    page_size = String.to_integer(size_str)

    # Reset to first page with new size
    case EveDmv.Pagination.CursorPaginator.paginate_corporation_members(
           corporation_id,
           page_size: page_size
         ) do
      paginator ->
        pagination = EveDmv.Pagination.CursorPaginator.pagination_assigns(paginator)

        socket =
          socket
          |> stream(:members, pagination.items, reset: true, dom_id: &"member-#{&1.character_id}")
          |> assign(:members_pagination, pagination)
          |> assign(:members_page_size, page_size)

        {:noreply, socket}
    end
  end

  # Activity pagination handlers
  def handle_event("load_more_activity", %{"cursor" => cursor}, socket) do
    corporation_id = socket.assigns.corporation_id

    # Load more activity using cursor pagination
    case load_more_recent_activity(corporation_id, cursor) do
      {:ok, activities} ->
        socket =
          stream(socket, :recent_activity, activities,
            at: -1,
            dom_id: &"activity-#{&1.killmail_id}-#{&1.character_id}"
          )

        {:noreply, socket}

      {:error, _reason} ->
        {:noreply, put_flash(socket, :error, "Failed to load more activity")}
    end
  end

  @impl Phoenix.LiveView
  def handle_event("force_refresh", _params, socket) do
    corporation_id = socket.assigns.corporation_id
    # Clear cache for this corporation
    AnalysisCache.invalidate_corporation(corporation_id)
    # Also clear any corporation intelligence cache
    CorporationIntelligence.clear_corporation_cache(corporation_id)
    # Redirect to reload the page with fresh data
    {:noreply, push_navigate(socket, to: ~p"/corporation/#{corporation_id}")}
  end

  # Private helper functions
  defp load_all_corporation_data(corporation_id) do
    try do
      # Load all data using the optimized data loader
      data = DataLoader.load_corporation_data(corporation_id)

      # Load additional data that isn't in the optimized loader yet
      # (these can be migrated to the data loader later)
      # Temporary placeholder
      {:ok, location_stats} = DataLoader.load_corporation_info(corporation_id)
      # Temporary placeholder
      {:ok, victim_stats} = DataLoader.load_corporation_info(corporation_id)

      # Load intelligence data
      intelligence_data =
        case CorporationIntelligence.get_corporation_intelligence_report(corporation_id) do
          {:ok, data} -> data
          {:error, _} -> nil
        end

      # Load battle data
      battles = BattleDetector.detect_corporation_battles(corporation_id, 10)
      battle_stats = BattleDetector.get_corporation_battle_stats(corporation_id)
      fleet_doctrines = BattleDetector.get_corporation_fleet_doctrines(corporation_id)

      # Combine all data
      {:ok,
       Map.merge(data, %{
         location_stats: location_stats,
         victim_stats: victim_stats,
         intelligence: intelligence_data,
         battles: battles,
         battle_stats: battle_stats,
         fleet_doctrines: fleet_doctrines
       })}
    rescue
      error ->
        Logger.error("Error loading corporation data: #{inspect(error)}")
        {:error, error}
    end
  end

  defp load_corporation_info(corporation_id) do
    # First try to get from ESI for accurate member count
    esi_info =
      case EsiCorporationClient.get_corporation(corporation_id) do
        {:ok, corp} -> corp
        _ -> %{}
      end

    # Get additional info from recent killmail data
    case Ash.Query.for_read(Participant, :by_corporation, %{corporation_id: corporation_id})
         |> Ash.Query.limit(1)
         |> Ash.read(domain: Api) do
      {:ok, [participant | _]} ->
        %{
          corporation_id: corporation_id,
          corporation_name:
            Map.get(esi_info, :name) || participant.corporation_name || "Unknown Corporation",
          ticker: Map.get(esi_info, :ticker),
          member_count: Map.get(esi_info, :member_count, 0),
          alliance_id: participant.alliance_id,
          alliance_name: participant.alliance_name
        }

      {:ok, []} ->
        %{
          corporation_id: corporation_id,
          corporation_name: Map.get(esi_info, :name, "Unknown Corporation"),
          ticker: Map.get(esi_info, :ticker),
          member_count: Map.get(esi_info, :member_count, 0),
          alliance_id: Map.get(esi_info, :alliance_id),
          alliance_name: nil
        }

      {:error, _} ->
        %{
          corporation_id: corporation_id,
          corporation_name: Map.get(esi_info, :name, "Unknown Corporation"),
          ticker: Map.get(esi_info, :ticker),
          member_count: Map.get(esi_info, :member_count, 0),
          alliance_id: Map.get(esi_info, :alliance_id),
          alliance_name: nil
        }
    end
  end

  defp load_corp_members(corporation_id) do
    # Get corporation members with activity stats using optimized single query
    # Look back 90 days for comprehensive member data
    ninety_days_ago = DateTime.add(DateTime.utc_now(), -90, :day)
    Logger.info("Loading members for corp #{corporation_id} from #{ninety_days_ago}")

    case Ash.Query.for_read(Participant, :by_corporation, %{corporation_id: corporation_id})
         |> Ash.Query.filter(killmail_time >= ^ninety_days_ago)
         # Don't preload killmail_raw - it might be causing issues
         # |> Ash.Query.load([:killmail_raw])
         # Get more data for better aggregation
         |> Ash.Query.limit(1000)
         |> Ash.read(domain: Api) do
      {:ok, participants} ->
        Logger.debug("Found #{length(participants)} participants for corp #{corporation_id}")
        # Filter out entries without character_id
        valid_participants = Enum.filter(participants, & &1.character_id)
        Logger.debug("#{length(valid_participants)} participants have character_id")

        # Preload all character names to avoid N+1 queries
        BatchNameResolver.preload_participant_names(valid_participants)
        # Group by character and aggregate stats
        members =
          valid_participants
          |> Enum.group_by(& &1.character_id)
          |> Enum.map(fn {character_id, char_participants} ->
            kills = Enum.count(char_participants, &(not &1.is_victim))
            losses = Enum.count(char_participants, & &1.is_victim)

            latest_activity =
              case char_participants |> Enum.map(& &1.killmail_time) |> Enum.filter(& &1) do
                [] -> nil
                times -> Enum.max(times, DateTime)
              end

            # Use cached name resolution
            character_name = NameResolver.character_name(character_id)

            %{
              character_id: character_id,
              character_name: character_name,
              total_kills: kills,
              total_losses: losses,
              total_activity: kills + losses,
              latest_activity: latest_activity
            }
          end)
          |> Enum.sort_by(& &1.total_activity, :desc)
          |> Enum.take(50)

        Logger.debug("Returning #{length(members)} members")
        members

      {:error, reason} ->
        Logger.error("Failed to load corp members: #{inspect(reason)}")
        []
    end
  end

  defp load_recent_activity(corporation_id) do
    # Get recent killmail activity using optimized query
    Logger.info("Loading recent activity for corp #{corporation_id}")

    case Ash.Query.for_read(Participant, :by_corporation, %{corporation_id: corporation_id})
         # Don't preload killmail_raw - it might be causing issues
         # |> Ash.Query.load([:killmail_raw])
         |> Ash.Query.sort(killmail_time: :desc)
         |> Ash.Query.limit(20)
         |> Ash.read(domain: Api) do
      {:ok, participants} ->
        Logger.debug("Found #{length(participants)} recent activities for corp #{corporation_id}")
        # Filter out entries without character_id
        valid_participants = Enum.filter(participants, & &1.character_id)
        # Preload all names to avoid N+1 queries
        BatchNameResolver.preload_participant_names(valid_participants)
        # Load activities with solar system information
        activities = load_activities_with_system_info(valid_participants)
        Logger.debug("Returning #{length(activities)} recent activities")
        activities

      {:error, reason} ->
        Logger.error("Failed to load corp members: #{inspect(reason)}")
        []
    end
  end


  defp calculate_isk_values(kill_ids, loss_ids) do
    # Calculate real ISK values from killmail data
    isk_destroyed = calculate_isk_for_participants(kill_ids, false)
    isk_lost = calculate_isk_for_participants(loss_ids, true)
    {isk_destroyed, isk_lost}
  end

  defp calculate_isk_for_participants(participant_ids, is_victim) when is_list(participant_ids) do
    if Enum.empty?(participant_ids) do
      0
    else
      # Query killmail ISK values for participants
      query = """
      SELECT COALESCE(SUM(k.zkb_total_value), 0) as total_isk
      FROM participants p
      JOIN killmails_raw k ON p.killmail_id = k.killmail_id AND p.killmail_time = k.killmail_time
      WHERE p.id = ANY($1) AND p.is_victim = $2
      """

      case SQL.query(Repo, query, [participant_ids, is_victim]) do
        {:ok, %{rows: [[isk_value]]}} when is_number(isk_value) ->
          round(isk_value)

        {:ok, %{rows: [[nil]]}} ->
          0

        {:error, _reason} ->
          # Fallback to placeholder calculation if query fails
          length(participant_ids) * 50_000_000
      end
    end
  end

  # Helper functions
  defp round_value(value, precision) when is_number(value) do
    if is_float(value) do
      Float.round(value, precision)
    else
      # Convert integer to float for rounding
      Float.round(value * 1.0, precision)
    end
  end

  defp round_value(_value, _precision), do: 0.0

  defp safe_float_round(value, precision) when is_float(value) do
    Float.round(value, precision)
  end

  defp safe_float_round(value, _precision) when is_integer(value) do
    value * 1.0
  end

  # Template helper functions (using FormatHelpers for numbers and ISK)
  def activity_indicator(activity_count) do
    cond do
      activity_count >= 50 -> {"🔥", "text-red-400"}
      activity_count >= 20 -> {"⚡", "text-yellow-400"}
      activity_count >= 5 -> {"✅", "text-green-400"}
      activity_count > 0 -> {"📍", "text-blue-400"}
      true -> {"💤", "text-gray-500"}
    end
  end

  def activity_level(activity_count) do
    cond do
      activity_count >= 50 -> "Very High"
      activity_count >= 20 -> "High"
      activity_count >= 5 -> "Active"
      activity_count > 0 -> "Low"
      true -> "Inactive"
    end
  end

  # Using TimeFormatter.format_friendly_time for time formatting
  def activity_type_badge(is_kill) do
    if is_kill do
      {"🎯 Kill", "bg-green-600 text-white"}
    else
      {"💀 Loss", "bg-red-600 text-white"}
    end
  end

  defp load_location_stats(corporation_id) do
    # Get activity counts by solar system using Ash
    thirty_days_ago = DateTime.add(DateTime.utc_now(), -30, :day)

    case Ash.Query.for_read(Participant, :by_corporation, %{corporation_id: corporation_id})
         |> Ash.Query.filter(killmail_time >= ^thirty_days_ago)
         |> Ash.read(domain: Api) do
      {:ok, participants} ->
        # Group by solar system and aggregate stats
        system_groups = Enum.group_by(participants, & &1.solar_system_id)
        # Batch load all system names to avoid N+1 queries
        system_ids = Enum.filter(Map.keys(system_groups), & &1)
        system_names = get_system_names(system_ids)

        system_groups
        |> Enum.map(fn {system_id, system_participants} ->
          kills = Enum.count(system_participants, &(not &1.is_victim))
          losses = Enum.count(system_participants, & &1.is_victim)

          %{
            solar_system_id: system_id,
            solar_system_name: Map.get(system_names, system_id, "Unknown System #{system_id}"),
            activity_count: length(system_participants),
            kills: kills,
            losses: losses
          }
        end)
        |> Enum.sort_by(& &1.activity_count, :desc)
        |> Enum.take(20)

      {:error, reason} ->
        Logger.error("Failed to load corp members: #{inspect(reason)}")
        []
    end
  end

  defp load_victim_corporation_stats(corporation_id) do
    # Get top victim corporations using Ash
    thirty_days_ago = DateTime.add(DateTime.utc_now(), -30, :day)
    # First get all our corporation's attackers (is_victim = false)
    case Ash.Query.for_read(Participant, :by_corporation, %{corporation_id: corporation_id})
         |> Ash.Query.filter(killmail_time >= ^thirty_days_ago and is_victim == false)
         |> Ash.read(domain: Api) do
      {:ok, our_attackers} ->
        # Get unique killmail IDs where our corp attacked
        our_killmail_ids = our_attackers |> Enum.map(& &1.killmail_id) |> Enum.uniq()
        # Now get all victims from those killmails
        case Ash.Query.for_read(Participant, :read)
             |> Ash.Query.filter(killmail_id in ^our_killmail_ids and is_victim == true)
             |> Ash.read(domain: Api) do
          {:ok, victims} ->
            # Group by victim corporation and count kills
            victims
            |> Enum.group_by(&{&1.corporation_id, &1.corporation_name})
            |> Enum.map(fn {{corp_id, corp_name}, victim_participants} ->
              kill_count =
                victim_participants |> Enum.map(& &1.killmail_id) |> Enum.uniq() |> length()

              %{
                corporation_id: corp_id,
                corporation_name: corp_name || "Unknown Corporation",
                kill_count: kill_count
              }
            end)
            |> Enum.sort_by(& &1.kill_count, :desc)
            |> Enum.take(10)

          {:error, _} ->
            []
        end

      {:error, reason} ->
        Logger.error("Failed to load corp members: #{inspect(reason)}")
        []
    end
  end

  defp get_system_names(system_ids) do
    # Batch load system names to avoid N+1 queries
    NameResolver.system_names(system_ids)
  end


  # Sprint 15A: Helper function for loading more activity with pagination
  defp load_more_recent_activity(corporation_id, cursor) do
    try do
      activities =
        EveDmv.Pagination.CursorPaginator.paginate_character_activity(
          corporation_id,
          after: cursor,
          page_size: 50
        )

      {:ok, activities.edges |> Enum.map(& &1.node)}
    rescue
      _ -> {:error, :pagination_failed}
    end
  end

  defp calculate_participation_data(members, corp_info) do
    # Use the actual number of members we have data for
    members_with_data = length(members)
    # Get the actual ESI member count
    total_corp_members = Map.get(corp_info || %{}, :member_count, members_with_data)
    # Use total corp members for participation rates if we have ESI data
    # This gives a more accurate representation of corp activity
    participation_base =
      if total_corp_members > 0 && total_corp_members >= members_with_data do
        total_corp_members
      else
        members_with_data
      end

    # Calculate PvP participation (members with any activity vs total members)
    pvp_participants = Enum.count(members, &(&1.total_activity > 0))

    pvp_rate =
      if participation_base > 0, do: pvp_participants / participation_base * 100, else: 0.0

    # Calculate fleet participation (members with 3+ activities suggesting group play)
    fleet_participants = Enum.count(members, &(&1.total_activity >= 3))

    fleet_rate =
      if participation_base > 0, do: fleet_participants / participation_base * 100, else: 0.0

    # Calculate corporate activity (active members with 5+ activities)
    active_participants = Enum.count(members, &(&1.total_activity >= 5))

    active_rate =
      if participation_base > 0, do: active_participants / participation_base * 100, else: 0.0

    # Overall participation score (weighted average)
    overall_score = pvp_rate * 0.3 + fleet_rate * 0.4 + active_rate * 0.3

    %{
      pvp_participation: %{participants: pvp_participants, rate: Float.round(pvp_rate, 1)},
      fleet_participation: %{participants: fleet_participants, rate: Float.round(fleet_rate, 1)},
      corporate_activity: %{participants: active_participants, rate: Float.round(active_rate, 1)},
      overall_participation_score: Float.round(overall_score, 1),
      members_with_data: members_with_data,
      total_members: total_corp_members
    }
  end

  def format_doctrine_name(doctrine) do
    doctrine
    |> to_string()
    |> String.replace("_", " ")
    |> String.split()
    |> Enum.map_join(" ", &String.capitalize/1)
  end

  def get_doctrine_description(doctrine) do
    case doctrine do
      :shield_kiting ->
        "Long-range shield tanked ships with high mobility and standoff capability"

      :armor_brawling ->
        "Close-range armor tanked ships focused on sustained DPS and tank"

      :ewar_heavy ->
        "Electronic warfare focused doctrine with force multiplication through disruption"

      :capital_escalation ->
        "Doctrine built around capital ship deployment and escalation scenarios"

      :alpha_strike ->
        "High alpha damage doctrine focused on quickly eliminating priority targets"

      :nano_gang ->
        "High speed, high mobility doctrine for hit-and-run tactics"

      :logistics_heavy ->
        "Doctrine emphasizing survivability through extensive logistics support"

      _ ->
        "Unknown doctrine pattern"
    end
  end

  def threat_level_color("Very High"), do: "text-red-500"
  def threat_level_color("High"), do: "text-orange-500"
  def threat_level_color("Moderate"), do: "text-yellow-500"
  def threat_level_color("Low"), do: "text-blue-500"
  def threat_level_color(_), do: "text-green-500"

  defp analyze_timezone_coverage(hourly_distribution) do
    # Use consistent timezone blocks from TimezoneAnalyzer
    # EUTZ: 16:00-20:00
    # USTZ: 21:00-03:00 (wraps around midnight)
    # AUTZ: 08:00-14:00
    timezone_blocks = %{
      "EU Prime (16:00-20:00)" => 16..20,
      "US Prime (21:00-03:00)" => [21, 22, 23, 0, 1, 2, 3],
      "AUTZ Prime (08:00-14:00)" => 8..14
    }

    # Check each timezone block for activity
    {coverage_strengths, coverage_gaps} =
      Enum.reduce(timezone_blocks, {[], []}, fn {tz_name, hours}, {strengths, gaps} ->
        hours_list = if is_list(hours), do: hours, else: Enum.to_list(hours)

        total_activity =
          hours_list |> Enum.map(&Map.get(hourly_distribution, &1, 0)) |> Enum.sum()

        if total_activity >= 5 do
          {[tz_name | strengths], gaps}
        else
          {strengths, [tz_name | gaps]}
        end
      end)

    %{
      coverage_strengths: Enum.reverse(coverage_strengths),
      coverage_gaps: Enum.reverse(coverage_gaps)
    }
  end

  defp load_activities_with_system_info(participants) do
    # Get killmail IDs and times for query
    killmail_data =
      participants
      |> Enum.map(&{&1.killmail_id, &1.killmail_time})
      |> Enum.uniq()

    # Query for solar system IDs
    system_lookup = get_solar_systems_for_killmails(killmail_data)

    # Preload ship names to avoid N+1 queries
    ship_type_ids =
      participants |> Enum.map(& &1.ship_type_id) |> Enum.filter(& &1) |> Enum.uniq()

    NameResolver.ship_names(ship_type_ids)

    # Preload system names to avoid N+1 queries
    system_ids = system_lookup |> Map.values() |> Enum.filter(& &1) |> Enum.uniq()
    NameResolver.system_names(system_ids)

    # Build activities with system info (names are now cached)
    Enum.map(participants, fn p ->
      solar_system_id = Map.get(system_lookup, p.killmail_id)

      %{
        character_id: p.character_id,
        character_name: NameResolver.character_name(p.character_id),
        ship_name: NameResolver.ship_name(p.ship_type_id),
        is_kill: not p.is_victim,
        timestamp: p.killmail_time,
        killmail_id: p.killmail_id,
        solar_system_name:
          if(solar_system_id,
            do: NameResolver.system_name(solar_system_id),
            else: "Unknown"
          )
      }
    end)
  end

  defp get_solar_systems_for_killmails(killmail_data) when is_list(killmail_data) do
    if Enum.empty?(killmail_data) do
      %{}
    else
      # Build query to get solar system IDs for killmails
      killmail_ids = Enum.map(killmail_data, &elem(&1, 0))

      query = """
      SELECT killmail_id, solar_system_id 
      FROM killmails_raw 
      WHERE killmail_id = ANY($1)
      """

      case SQL.query(Repo, query, [killmail_ids]) do
        {:ok, %{rows: rows}} ->
          Enum.into(rows, %{}, fn [killmail_id, system_id] -> {killmail_id, system_id} end)

        {:error, _reason} ->
          %{}
      end
    end
  end
end
